{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Jun  4 09:50:40 2023       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 530.51.01              Driver Version: 532.03       CUDA Version: 12.1     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                  Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf            Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3090         On | 00000000:09:00.0  On |                  N/A |\n",
      "| 95%   41C    P3              128W / 350W|   9886MiB / 24576MiB |     58%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A        22      G   /Xwayland                                 N/A      |\n",
      "|    0   N/A  N/A        26      G   /Xwayland                                 N/A      |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets, transforms\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten(nn.Module):\n",
    "    def forward(self, x): return x.view(x.size(0), -1)\n",
    "\n",
    "class Net(nn.Sequential):\n",
    "    def __init__(self, i):\n",
    "        super().__init__(\n",
    "            nn.Conv2d(3, 32, 3, 1), nn.ReLU(),\n",
    "            *[layer for _ in range(i) for layer in [nn.Conv2d(32, 32, 1, 1), nn.ReLU()]],\n",
    "            nn.MaxPool2d(2), nn.Dropout(0.25),\n",
    "            nn.Conv2d(32, 64, 3, 1), nn.MaxPool2d(2), nn.Dropout(0.25),\n",
    "            Flatten(), nn.Linear(57600, 128), nn.ReLU(), nn.Dropout(0.5),\n",
    "            nn.Linear(128, 2), nn.LogSoftmax(dim=1) )\n",
    "\n",
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    losses = []\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # if batch_idx % 100 == 0:\n",
    "        #     print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "        #         epoch, batch_idx*len(data), len(train_loader.dataset),\n",
    "        #         100. * batch_idx/len(train_loader), loss.item()))\n",
    "        losses.append(loss.item())\n",
    "    return sum(losses)/len(losses)\n",
    "\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item()\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            \n",
    "            # Store predictions and targets for recall calculation\n",
    "            all_preds.extend(pred.cpu().numpy())\n",
    "            all_targets.extend(target.cpu().numpy())\n",
    "    \n",
    "    recalls = recall_score(all_targets, all_preds, average=None)  # compute recall for each class\n",
    "    class_recall = recalls[1]  # replace 0 with the index of the class you're interested in\n",
    "\n",
    "    # print('\\nTest set: Average loss: {:.4f}, Recall: {:.2f}\\n'.format(\n",
    "    #     test_loss/len(test_loader.dataset), class_recall))\n",
    "\n",
    "    return class_recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data_dir, transforms=None):\n",
    "        self.data_dir = data_dir\n",
    "        self.data_info = self.get_img_info(data_dir)\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        path_img, label = self.data_info.iloc[item][1:3]\n",
    "        label = int(label)\n",
    "        path_img = os.path.join(self.data_dir, path_img)\n",
    "        image = Image.open(path_img).convert('RGB') # Gray scale is enough for logic interpretation\n",
    "        # 使用定义好的transforms，对数据进行处理\n",
    "        if self.transforms is not None:\n",
    "            image = self.transforms(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_info)\n",
    "    \n",
    "    def get_img_info(self, data_dir):\n",
    "        path_dir = os.path.join(data_dir, 'label.csv')\n",
    "        return pd.read_csv(path_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_folder = \"dataset03\"\n",
    "exp_name = f\"{dataset_folder}_ablation_study_2\"\n",
    "\n",
    "if not os.path.exists(f'./models/{exp_name}'):\n",
    "    os.mkdir(f'./models/{exp_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = {'num_workers': 16}\n",
    "batch_size=128\n",
    "\n",
    "InDL = True\n",
    "if InDL:\n",
    "    transform = transforms.Compose(\n",
    "        [transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]) \n",
    "\n",
    "    trainset = MyDataset(f\"data/train/{dataset_folder}\", transform)\n",
    "    testset = MyDataset(f\"data/test/{dataset_folder}\", transform)\n",
    "else:\n",
    "    transform=transforms.Compose(\n",
    "        [transforms.ToTensor(),transforms.Normalize((0.1307,), (0.3081,))])\n",
    "\n",
    "    trainset = datasets.MNIST(root='data/mnist', train=True, download=True, transform=transform)\n",
    "    testset = datasets.MNIST(root='data/mnist', train=False, download=True, transform=transform)\n",
    "    \n",
    "    # trainset = datasets.CIFAR10(root='data/cifar10', train=True, download=True, transform=transform)\n",
    "    # testset = datasets.CIFAR10(root='data/cifar10', train=False, download=True, transform=transform)\n",
    "    \n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, **kwargs)\n",
    "test_loader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=True, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 73/100 [05:51<02:20,  5.20s/it]"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "epochs, lr = 100, 1e-4\n",
    "\n",
    "for i in range(10):\n",
    "    df = pd.DataFrame(columns=['Loss', 'Recall'])\n",
    "    \n",
    "    model_name = f\"{i}-net\"\n",
    "    if InDL:\n",
    "        model_name = f\"{model_name}-InDL\"\n",
    "    else:\n",
    "        model_name = f\"{model_name}-MNIST\"\n",
    "\n",
    "    model = Net(i).to(device)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "    \n",
    "    model_path = f'./models/{exp_name}/{model_name}.pt'\n",
    "    history_path = f'./models/{exp_name}/{model_name}_history.csv'\n",
    "\n",
    "    if os.path.exists(history_path):\n",
    "        df = pd.read_csv(history_path)\n",
    "    else:\n",
    "        previous_best_recall = 0\n",
    "        for epoch in tqdm(range(1, epochs+1)):\n",
    "            loss = train(model, device, train_loader, optimizer, epoch)\n",
    "            recall = test(model, device, test_loader)\n",
    "            \n",
    "            df.loc[len(df)] = [loss, recall]\n",
    "            \n",
    "            if recall > previous_best_recall:\n",
    "                previous_best_recall = recall\n",
    "                torch.save(model.state_dict(), model_path)\n",
    "                \n",
    "        df.to_csv(history_path, index=False)\n",
    "\n",
    "    # Assuming df is your DataFrame and it has columns 'Loss' and 'Class 0 Recall'\n",
    "\n",
    "    fig, ax1 = plt.subplots()\n",
    "\n",
    "    # Plot Loss\n",
    "    sns.lineplot(data=df, x=df.index, y='Loss', ax=ax1, color='blue')\n",
    "    ax1.set_ylabel('Loss', color='blue')\n",
    "    ax1.tick_params(axis='y', labelcolor='blue')\n",
    "\n",
    "    # Create a second y-axis and plot Recall on it\n",
    "    ax2 = ax1.twinx()\n",
    "    sns.lineplot(data=df, x=df.index, y='Recall', ax=ax2, color='red')\n",
    "    ax2.set_ylabel('Recall', color='red')\n",
    "    ax2.tick_params(axis='y', labelcolor='red')\n",
    "    \n",
    "    ax1.set_xlabel('Epochs')\n",
    "\n",
    "    plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0-net-InDL\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.81      0.89       282\n",
      "           1       0.69      0.99      0.81       118\n",
      "\n",
      "    accuracy                           0.86       400\n",
      "   macro avg       0.84      0.90      0.85       400\n",
      "weighted avg       0.90      0.86      0.87       400\n",
      "\n",
      "1-net-InDL\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.82      0.90       282\n",
      "           1       0.69      0.99      0.82       118\n",
      "\n",
      "    accuracy                           0.87       400\n",
      "   macro avg       0.84      0.90      0.86       400\n",
      "weighted avg       0.91      0.87      0.87       400\n",
      "\n",
      "2-net-InDL\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.81      0.89       282\n",
      "           1       0.69      0.98      0.81       118\n",
      "\n",
      "    accuracy                           0.86       400\n",
      "   macro avg       0.84      0.90      0.85       400\n",
      "weighted avg       0.90      0.86      0.87       400\n",
      "\n",
      "3-net-InDL\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.89      0.93       282\n",
      "           1       0.78      0.94      0.85       118\n",
      "\n",
      "    accuracy                           0.91       400\n",
      "   macro avg       0.88      0.92      0.89       400\n",
      "weighted avg       0.92      0.91      0.91       400\n",
      "\n",
      "4-net-InDL\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.86      0.91       282\n",
      "           1       0.73      0.91      0.81       118\n",
      "\n",
      "    accuracy                           0.88       400\n",
      "   macro avg       0.84      0.88      0.86       400\n",
      "weighted avg       0.89      0.88      0.88       400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def evaluate_model(model, dataloader, device):\n",
    "    model.eval()  # set the model to evaluation mode\n",
    "    \n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():  # don't calculate gradients\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            _, predictions = torch.max(outputs, 1)\n",
    "            \n",
    "            all_predictions.extend(predictions.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    print(classification_report(all_labels, all_predictions))\n",
    "\n",
    "for i in range(5):\n",
    "    model_name = f\"{i}-net\"\n",
    "    if InDL:\n",
    "        model_name = f\"{model_name}-InDL\"\n",
    "    else:\n",
    "        model_name = f\"{model_name}-MNIST\"\n",
    "        \n",
    "    state_dict = torch.load(f\"models/{exp_name}/{model_name}.pt\")\n",
    "    model = Net(i).to(device)\n",
    "    model.load_state_dict(state_dict)\n",
    "    \n",
    "    print(model_name)\n",
    "\n",
    "    # Assuming you have a model, dataloader and device (CPU or CUDA) defined\n",
    "    evaluate_model(model, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
