{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Jun  4 11:33:16 2023       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 530.51.01              Driver Version: 532.03       CUDA Version: 12.1     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                  Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf            Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3090         On | 00000000:09:00.0  On |                  N/A |\n",
      "| 95%   44C    P2              319W / 350W|   8346MiB / 24576MiB |     77%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A        22      G   /Xwayland                                 N/A      |\n",
      "|    0   N/A  N/A        26      G   /Xwayland                                 N/A      |\n",
      "|    0   N/A  N/A      1676      C   /python3.10                               N/A      |\n",
      "|    0   N/A  N/A     24343      C   /python3.10                               N/A      |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets, transforms\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten(nn.Module):\n",
    "    def forward(self, x): return x.view(x.size(0), -1)\n",
    "\n",
    "class Net(nn.Sequential):\n",
    "    def __init__(self, i):\n",
    "        super().__init__(\n",
    "            nn.Conv2d(1, 32, 3, 1), nn.ReLU(),\n",
    "            *[layer for _ in range(i) for layer in [nn.Conv2d(32, 32, 1, 1), nn.ReLU()]],\n",
    "            nn.Conv2d(32, 64, 3, 1), nn.MaxPool2d(2), nn.Dropout(0.25),\n",
    "            Flatten(), nn.Linear(9216, 128), nn.ReLU(), nn.Dropout(0.5),\n",
    "            nn.Linear(128, 10), nn.LogSoftmax(dim=1) )\n",
    "\n",
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    losses = []\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # if batch_idx % 100 == 0:\n",
    "        #     print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "        #         epoch, batch_idx*len(data), len(train_loader.dataset),\n",
    "        #         100. * batch_idx/len(train_loader), loss.item()))\n",
    "        losses.append(loss.item())\n",
    "    return sum(losses)/len(losses)\n",
    "\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item()\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            \n",
    "            # Store predictions and targets for recall calculation\n",
    "            all_preds.extend(pred.cpu().numpy())\n",
    "            all_targets.extend(target.cpu().numpy())\n",
    "    \n",
    "    recalls = recall_score(all_targets, all_preds, average=None)  # compute recall for each class\n",
    "    class_recall = recalls[1]  # replace 0 with the index of the class you're interested in\n",
    "\n",
    "    # print('\\nTest set: Average loss: {:.4f}, Recall: {:.2f}\\n'.format(\n",
    "    #     test_loss/len(test_loader.dataset), class_recall))\n",
    "\n",
    "    return class_recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data_dir, transforms=None):\n",
    "        self.data_dir = data_dir\n",
    "        self.data_info = self.get_img_info(data_dir)\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        path_img, label = self.data_info.iloc[item][1:3]\n",
    "        label = int(label)\n",
    "        path_img = os.path.join(self.data_dir, path_img)\n",
    "        image = Image.open(path_img).convert('RGB') # Gray scale is enough for logic interpretation\n",
    "        # 使用定义好的transforms，对数据进行处理\n",
    "        if self.transforms is not None:\n",
    "            image = self.transforms(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_info)\n",
    "    \n",
    "    def get_img_info(self, data_dir):\n",
    "        path_dir = os.path.join(data_dir, 'label.csv')\n",
    "        return pd.read_csv(path_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_folder = \"dataset03\"\n",
    "exp_name = f\"{dataset_folder}_ablation_study_2_ref\"\n",
    "\n",
    "if not os.path.exists(f'./models/{exp_name}'):\n",
    "    os.mkdir(f'./models/{exp_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = {'num_workers': 16}\n",
    "batch_size=128\n",
    "\n",
    "InDL = False\n",
    "if InDL:\n",
    "    transform = transforms.Compose(\n",
    "        [transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]) \n",
    "\n",
    "    trainset = MyDataset(f\"data/train/{dataset_folder}\", transform)\n",
    "    testset = MyDataset(f\"data/test/{dataset_folder}\", transform)\n",
    "else:\n",
    "    transform=transforms.Compose(\n",
    "        [transforms.ToTensor(),transforms.Normalize((0.1307,), (0.3081,))])\n",
    "\n",
    "    trainset = datasets.MNIST(root='data/mnist', train=True, download=True, transform=transform)\n",
    "    testset = datasets.MNIST(root='data/mnist', train=False, download=True, transform=transform)\n",
    "    \n",
    "    # trainset = datasets.CIFAR10(root='data/cifar10', train=True, download=True, transform=transform)\n",
    "    # testset = datasets.CIFAR10(root='data/cifar10', train=False, download=True, transform=transform)\n",
    "    \n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, **kwargs)\n",
    "test_loader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=True, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     model_name \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mmodel_name\u001b[39m}\u001b[39;00m\u001b[39m-MNIST\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m---> 16\u001b[0m model \u001b[39m=\u001b[39m Net(i)\u001b[39m.\u001b[39;49mto(device)\n\u001b[1;32m     17\u001b[0m optimizer \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mAdamW(model\u001b[39m.\u001b[39mparameters(), lr\u001b[39m=\u001b[39mlr)\n\u001b[1;32m     19\u001b[0m model_path \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m./models/\u001b[39m\u001b[39m{\u001b[39;00mexp_name\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mmodel_name\u001b[39m}\u001b[39;00m\u001b[39m.pt\u001b[39m\u001b[39m'\u001b[39m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1145\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1141\u001b[0m         \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   1142\u001b[0m                     non_blocking, memory_format\u001b[39m=\u001b[39mconvert_to_format)\n\u001b[1;32m   1143\u001b[0m     \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m, non_blocking)\n\u001b[0;32m-> 1145\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_apply(convert)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:797\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    795\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_apply\u001b[39m(\u001b[39mself\u001b[39m, fn):\n\u001b[1;32m    796\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[0;32m--> 797\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[1;32m    799\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    800\u001b[0m         \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    801\u001b[0m             \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    802\u001b[0m             \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    808\u001b[0m             \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:820\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    816\u001b[0m \u001b[39m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    817\u001b[0m \u001b[39m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    818\u001b[0m \u001b[39m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    819\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m--> 820\u001b[0m     param_applied \u001b[39m=\u001b[39m fn(param)\n\u001b[1;32m    821\u001b[0m should_use_set_data \u001b[39m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    822\u001b[0m \u001b[39mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1143\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1140\u001b[0m \u001b[39mif\u001b[39;00m convert_to_format \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m t\u001b[39m.\u001b[39mdim() \u001b[39min\u001b[39;00m (\u001b[39m4\u001b[39m, \u001b[39m5\u001b[39m):\n\u001b[1;32m   1141\u001b[0m     \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   1142\u001b[0m                 non_blocking, memory_format\u001b[39m=\u001b[39mconvert_to_format)\n\u001b[0;32m-> 1143\u001b[0m \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39;49mto(device, dtype \u001b[39mif\u001b[39;49;00m t\u001b[39m.\u001b[39;49mis_floating_point() \u001b[39mor\u001b[39;49;00m t\u001b[39m.\u001b[39;49mis_complex() \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m, non_blocking)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "epochs, lr = 100, 1e-4\n",
    "\n",
    "for i in range(10):\n",
    "    df = pd.DataFrame(columns=['Loss', 'Recall'])\n",
    "    \n",
    "    model_name = f\"{i}-net\"\n",
    "    if InDL:\n",
    "        model_name = f\"{model_name}-InDL\"\n",
    "    else:\n",
    "        model_name = f\"{model_name}-MNIST\"\n",
    "\n",
    "    model = Net(i).to(device)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "    \n",
    "    model_path = f'./models/{exp_name}/{model_name}.pt'\n",
    "    history_path = f'./models/{exp_name}/{model_name}_history.csv'\n",
    "\n",
    "    if os.path.exists(history_path):\n",
    "        df = pd.read_csv(history_path)\n",
    "    else:\n",
    "        previous_best_recall = 0\n",
    "        for epoch in tqdm(range(1, epochs+1)):\n",
    "            loss = train(model, device, train_loader, optimizer, epoch)\n",
    "            recall = test(model, device, test_loader)\n",
    "            \n",
    "            df.loc[len(df)] = [loss, recall]\n",
    "            \n",
    "            if recall > previous_best_recall:\n",
    "                previous_best_recall = recall\n",
    "                torch.save(model.state_dict(), model_path)\n",
    "                \n",
    "        df.to_csv(history_path, index=False)\n",
    "\n",
    "    # Assuming df is your DataFrame and it has columns 'Loss' and 'Class 0 Recall'\n",
    "\n",
    "    fig, ax1 = plt.subplots()\n",
    "\n",
    "    # Plot Loss\n",
    "    sns.lineplot(data=df, x=df.index, y='Loss', ax=ax1, color='blue')\n",
    "    ax1.set_ylabel('Loss', color='blue')\n",
    "    ax1.tick_params(axis='y', labelcolor='blue')\n",
    "\n",
    "    # Create a second y-axis and plot Recall on it\n",
    "    ax2 = ax1.twinx()\n",
    "    sns.lineplot(data=df, x=df.index, y='Recall', ax=ax2, color='red')\n",
    "    ax2.set_ylabel('Recall', color='red')\n",
    "    ax2.tick_params(axis='y', labelcolor='red')\n",
    "    \n",
    "    ax1.set_xlabel('Epochs')\n",
    "\n",
    "    plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0-net-InDL\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.75      0.86       282\n",
      "           1       0.63      1.00      0.77       118\n",
      "\n",
      "    accuracy                           0.82       400\n",
      "   macro avg       0.81      0.88      0.81       400\n",
      "weighted avg       0.89      0.82      0.83       400\n",
      "\n",
      "1-net-InDL\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.78      0.88       282\n",
      "           1       0.66      0.99      0.79       118\n",
      "\n",
      "    accuracy                           0.84       400\n",
      "   macro avg       0.83      0.89      0.83       400\n",
      "weighted avg       0.90      0.84      0.85       400\n",
      "\n",
      "2-net-InDL\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.84      0.91       282\n",
      "           1       0.72      0.98      0.83       118\n",
      "\n",
      "    accuracy                           0.88       400\n",
      "   macro avg       0.85      0.91      0.87       400\n",
      "weighted avg       0.91      0.88      0.88       400\n",
      "\n",
      "3-net-InDL\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.75      0.85       282\n",
      "           1       0.62      0.98      0.76       118\n",
      "\n",
      "    accuracy                           0.82       400\n",
      "   macro avg       0.81      0.87      0.81       400\n",
      "weighted avg       0.88      0.82      0.83       400\n",
      "\n",
      "4-net-InDL\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.85      0.91       282\n",
      "           1       0.72      0.95      0.82       118\n",
      "\n",
      "    accuracy                           0.88       400\n",
      "   macro avg       0.85      0.90      0.86       400\n",
      "weighted avg       0.90      0.88      0.88       400\n",
      "\n",
      "5-net-InDL\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.82      0.89       282\n",
      "           1       0.69      0.95      0.80       118\n",
      "\n",
      "    accuracy                           0.86       400\n",
      "   macro avg       0.83      0.89      0.85       400\n",
      "weighted avg       0.89      0.86      0.87       400\n",
      "\n",
      "6-net-InDL\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.80      0.88       282\n",
      "           1       0.66      0.94      0.78       118\n",
      "\n",
      "    accuracy                           0.84       400\n",
      "   macro avg       0.82      0.87      0.83       400\n",
      "weighted avg       0.88      0.84      0.85       400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def evaluate_model(model, dataloader, device):\n",
    "    model.eval()  # set the model to evaluation mode\n",
    "    \n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():  # don't calculate gradients\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            _, predictions = torch.max(outputs, 1)\n",
    "            \n",
    "            all_predictions.extend(predictions.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    print(classification_report(all_labels, all_predictions))\n",
    "\n",
    "for i in range(10):\n",
    "    model_name = f\"{i}-net\"\n",
    "    if InDL:\n",
    "        model_name = f\"{model_name}-InDL\"\n",
    "    else:\n",
    "        model_name = f\"{model_name}-MNIST\"\n",
    "        \n",
    "    if not os.path.exists(f\"models/{exp_name}/{model_name}.pt\"):\n",
    "        continue\n",
    "    state_dict = torch.load(f\"models/{exp_name}/{model_name}.pt\")\n",
    "    model = Net(i).to(device)\n",
    "    model.load_state_dict(state_dict)\n",
    "    \n",
    "    print(model_name)\n",
    "\n",
    "    # Assuming you have a model, dataloader and device (CPU or CUDA) defined\n",
    "    evaluate_model(model, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
