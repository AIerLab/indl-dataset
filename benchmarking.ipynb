{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmarking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Prepare working environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from scripts import Worker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No devices were found\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Datasets and visulisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data_dir, transforms=None):\n",
    "        self.data_dir = data_dir\n",
    "        self.data_info = self.get_img_info(data_dir)\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        path_img, label = self.data_info.iloc[item][1:3]\n",
    "        label = int(label)\n",
    "        path_img = os.path.join(self.data_dir, path_img)\n",
    "        image = Image.open(path_img).convert('RGB')\n",
    "        # 使用定义好的transforms，对数据进行处理\n",
    "        if self.transforms is not None:\n",
    "            image = self.transforms(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_info)\n",
    "    \n",
    "    def get_img_info(self, data_dir):\n",
    "        path_dir = os.path.join(data_dir, 'label.csv')\n",
    "        return pd.read_csv(path_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_folder = \"dataset03\"\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor()])\n",
    "    #  transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "\n",
    "trainset = MyDataset(f\"data/train/{dataset_folder}\", transform)\n",
    "testset = MyDataset(f\"data/test/{dataset_folder}\", transform)\n",
    "\n",
    "# trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=16, shuffle=True, num_workers=8)\n",
    "\n",
    "# testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=1, shuffle=False, num_workers=8)\n",
    "\n",
    "classes = (0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    1     0     0     0     1     0     0     1     1     0     0     0     1     0     0     0\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# 输出图像的函数\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# 随机获取训练图片\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# 显示图片\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "# 打印图片标签\n",
    "print(' '.join('%5s' % classes[labels[j]] for j in range(16)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['vgg11',\n",
       " 'vgg11_bn',\n",
       " 'vgg13',\n",
       " 'vgg13_bn',\n",
       " 'vgg16',\n",
       " 'vgg16_bn',\n",
       " 'vgg19',\n",
       " 'vgg19_bn']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timm.list_models('vgg*', pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_name = \"dataset03_benchmarking\"\n",
    "model_names = ['xception','densenet121','resnet50', 'vgg19','darknet53', ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xception\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.229409</td>\n",
       "      <td>0.907941</td>\n",
       "      <td>0.831000</td>\n",
       "      <td>00:40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.102479</td>\n",
       "      <td>0.102103</td>\n",
       "      <td>0.971000</td>\n",
       "      <td>00:43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "densenet121\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.224588</td>\n",
       "      <td>1469.251465</td>\n",
       "      <td>0.318500</td>\n",
       "      <td>01:31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/1 00:00&lt;?]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "      <progress value='416' class='' max='2000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      20.80% [416/2000 00:10&lt;00:38 0.1223]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for model_name in model_names:\n",
    "    print(model_name)\n",
    "    model = timm.create_model(model_name, num_classes=2)\n",
    "    worker = Worker(exp_name, model_name, model, trainloader, testloader, epochs=1)\n",
    "    worker.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xception\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(model_name)\n\u001b[1;32m     13\u001b[0m benchmark_dict[model_name] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(columns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m---> 15\u001b[0m state_dict \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodels/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mexp_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mmodel_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.pt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m model \u001b[38;5;241m=\u001b[39m timm\u001b[38;5;241m.\u001b[39mcreate_model(model_name, num_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     18\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(state_dict)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/serialization.py:712\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    710\u001b[0m             opened_file\u001b[38;5;241m.\u001b[39mseek(orig_position)\n\u001b[1;32m    711\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mload(opened_file)\n\u001b[0;32m--> 712\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpickle_load_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    713\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _legacy_load(opened_file, map_location, pickle_module, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/serialization.py:1046\u001b[0m, in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1044\u001b[0m unpickler \u001b[38;5;241m=\u001b[39m UnpicklerWrapper(data_file, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args)\n\u001b[1;32m   1045\u001b[0m unpickler\u001b[38;5;241m.\u001b[39mpersistent_load \u001b[38;5;241m=\u001b[39m persistent_load\n\u001b[0;32m-> 1046\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43munpickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1048\u001b[0m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_validate_loaded_sparse_tensors()\n\u001b[1;32m   1050\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/serialization.py:1016\u001b[0m, in \u001b[0;36m_load.<locals>.persistent_load\u001b[0;34m(saved_id)\u001b[0m\n\u001b[1;32m   1014\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m loaded_storages:\n\u001b[1;32m   1015\u001b[0m     nbytes \u001b[38;5;241m=\u001b[39m numel \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_element_size(dtype)\n\u001b[0;32m-> 1016\u001b[0m     \u001b[43mload_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_maybe_decode_ascii\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1018\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loaded_storages[key]\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/serialization.py:1001\u001b[0m, in \u001b[0;36m_load.<locals>.load_tensor\u001b[0;34m(dtype, numel, key, location)\u001b[0m\n\u001b[1;32m    997\u001b[0m storage \u001b[38;5;241m=\u001b[39m zip_file\u001b[38;5;241m.\u001b[39mget_storage_from_record(name, numel, torch\u001b[38;5;241m.\u001b[39m_UntypedStorage)\u001b[38;5;241m.\u001b[39mstorage()\u001b[38;5;241m.\u001b[39m_untyped()\n\u001b[1;32m    998\u001b[0m \u001b[38;5;66;03m# TODO: Once we decide to break serialization FC, we can\u001b[39;00m\n\u001b[1;32m    999\u001b[0m \u001b[38;5;66;03m# stop wrapping with _TypedStorage\u001b[39;00m\n\u001b[1;32m   1000\u001b[0m loaded_storages[key] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstorage\u001b[38;5;241m.\u001b[39m_TypedStorage(\n\u001b[0;32m-> 1001\u001b[0m     wrap_storage\u001b[38;5;241m=\u001b[39m\u001b[43mrestore_location\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m   1002\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/serialization.py:176\u001b[0m, in \u001b[0;36mdefault_restore_location\u001b[0;34m(storage, location)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault_restore_location\u001b[39m(storage, location):\n\u001b[1;32m    175\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _, _, fn \u001b[38;5;129;01min\u001b[39;00m _package_registry:\n\u001b[0;32m--> 176\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    177\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    178\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/serialization.py:152\u001b[0m, in \u001b[0;36m_cuda_deserialize\u001b[0;34m(obj, location)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_cuda_deserialize\u001b[39m(obj, location):\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m location\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m--> 152\u001b[0m         device \u001b[38;5;241m=\u001b[39m \u001b[43mvalidate_cuda_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    153\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(obj, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_torch_load_uninitialized\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    154\u001b[0m             storage_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(torch\u001b[38;5;241m.\u001b[39mcuda, \u001b[38;5;28mtype\u001b[39m(obj)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.8/site-packages/torch/serialization.py:136\u001b[0m, in \u001b[0;36mvalidate_cuda_device\u001b[0;34m(location)\u001b[0m\n\u001b[1;32m    133\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_get_device_index(location, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available():\n\u001b[0;32m--> 136\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAttempting to deserialize object on a CUDA \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    137\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice but torch.cuda.is_available() is False. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    138\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIf you are running on a CPU-only machine, \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    139\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mplease use torch.load with map_location=torch.device(\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124m) \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    140\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mto map your storages to the CPU.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    141\u001b[0m device_count \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mdevice_count()\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m device \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m device_count:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU."
     ]
    }
   ],
   "source": [
    "from fastai.vision import *\n",
    "from fastai.data.transforms import *\n",
    "\n",
    "\n",
    "exp_name = \"dataset03_benchmarking\"\n",
    "model_names = ['xception','densenet121','resnet50', 'vgg16','darknet53']\n",
    "\n",
    "benchmark_dict = {}\n",
    "\n",
    "for model_name in model_names:\n",
    "    print(model_name)\n",
    "    \n",
    "    benchmark_dict[model_name] = pd.DataFrame(columns = [\"value\", \"type\"])\n",
    "    \n",
    "    state_dict = torch.load(f\"models/{exp_name}/{model_name}.pt\")\n",
    "\n",
    "    model = timm.create_model(model_name, num_classes=2)\n",
    "    model.load_state_dict(state_dict)\n",
    "\n",
    "    worker = Worker(exp_name, model_name, model, trainloader, testloader)\n",
    "    worker.eval()\n",
    "    \n",
    "    path_dir = os.path.join(f\"data/test/{dataset_folder}\", 'label.csv')\n",
    "    info_df = pd.read_csv(path_dir)\n",
    "\n",
    "    testiter = iter(testloader)\n",
    "\n",
    "    FN_values = []\n",
    "    FP_values = []\n",
    "    TP_values = []\n",
    "    TN_values = []\n",
    "\n",
    "    for i in range(info_df.size-1):\n",
    "        images, labels = next(testiter, (None, None))\n",
    "\n",
    "        if images == None or labels == None:\n",
    "            break\n",
    "\n",
    "        label = info_df.iloc[i][2]\n",
    "        value = info_df.iloc[i][7]\n",
    "        images = images.to(device)\n",
    "        pred = worker.learner.model(images).argmax(1)[0]\n",
    "        if (pred != label):\n",
    "            if (label == 0):\n",
    "                benchmark_dict[model_name].loc[len(benchmark_dict[model_name]), benchmark_dict[model_name].columns] = value, 'FN'\n",
    "            else:\n",
    "                benchmark_dict[model_name].loc[len(benchmark_dict[model_name]), benchmark_dict[model_name].columns] = value, 'FP'\n",
    "                \n",
    "        else:\n",
    "            if (label == 0):\n",
    "                benchmark_dict[model_name].loc[len(benchmark_dict[model_name]), benchmark_dict[model_name].columns] = value, 'TN'\n",
    "                \n",
    "            else:\n",
    "                benchmark_dict[model_name].loc[len(benchmark_dict[model_name]), benchmark_dict[model_name].columns] = value, 'TP'\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "for model_name in model_names:\n",
    "    sns.kdeplot(data=benchmark_dict[model_name], x='value', hue='type', multiple='fill', bw_adjust = 0.2)\n",
    "\n",
    "    # plt.legend(['False Negative', 'True Negative'])\n",
    "    plt.xlabel (\"Red/Yellow Ratio\");\n",
    "    # plt.ylabel (\"\");\n",
    "    plt.title (f\"Negative Distribution: \\n{exp_name}-{model_name}\");\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "3196968d684371006099b3d55edeef8ed90365227a30deaef86e5d4aa8519be0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
